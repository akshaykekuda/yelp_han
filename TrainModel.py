# -*- coding: utf-8 -*-
"""TrainModel

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JkW85J7ZhjzUcKk7sSf8mSfFK6svNtND
"""

from __future__ import unicode_literals, print_function, division
from io import open
import unicodedata
import string
import re
import random

import numpy as np
# from matplotlib import pyplot as plt
from tqdm import tqdm
from Models import *
from Inference_fns import get_accuracy
from sklearn.utils import class_weight
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class TrainYelpModel():
    def __init__(self, dataloader_train, dataloader_dev, vocab_size, vec_size, weights_matrix):
        self.dataloader_train = dataloader_train
        self.dataloader_dev = dataloader_dev
        self.vocab_size = vocab_size
        self.vec_size = vec_size
        self.weights_matrix = weights_matrix

    def train_gru_model(self):
        encoder_output_size = 32
        encoder = EncoderRNN(self.vocab_size, self.vec_size, encoder_output_size, self.weights_matrix)
        classifier = BinaryClassifier(encoder_output_size)

        criterion = nn.CrossEntropyLoss()

        encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)
        classifier_optimizer = optim.Adam(classifier.parameters(), lr=0.001)

        epochs = 5
        for n in range(epochs):
            epoch_loss = 0
            for batch in tqdm(self.dataloader_train):
                encoder.zero_grad()
                classifier.zero_grad()
                loss = 0
                output, hidden = encoder(batch['indices'])
                output = output[:, -1, :]
                output = classifier(output)
                target = batch['category']
                loss += criterion(output, target)
                epoch_loss += loss.detach().item()
                loss.backward()
                encoder_optimizer.step()
                classifier_optimizer.step()

            print("Average loss at epoch {}: {}".format(n, epoch_loss / len(self.dataloader_train)))
            acc = get_accuracy(self.dataloader_train, encoder, classifier)
            print("Average accuracy at epoch {}: {}".format(n, acc))

        return encoder, classifier

    def train_gru_attention(self):

        encoder_output_size = 32
        encoder = GRUAttention(self.vocab_size, self.vec_size, encoder_output_size, self.weights_matrix)
        criterion = nn.CrossEntropyLoss()
        encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)
        epochs = 5
        for n in range(epochs):
            epoch_loss = 0
            for batch in tqdm(self.dataloader_train):
                encoder.zero_grad()
                loss = 0
                output, scores = encoder(batch['indices'])
                target = batch['category']
                loss += criterion(output, target)
                epoch_loss += loss.detach().item()
                loss.backward()
                encoder_optimizer.step()

            print("Average loss at epoch {}: {}".format(n, epoch_loss / len(self.dataloader_train)))
            acc = get_accuracy(self.dataloader_train, encoder)
            print("Average accuracy at epoch {}: {}".format(n, acc))

        return encoder

