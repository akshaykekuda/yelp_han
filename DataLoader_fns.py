# -*- coding: utf-8 -*-
"""DataLoader_fns

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t2vWLuHjJ9f2XaKZ75UHjFK3AWDiJv2M
"""

import torch
from torchtext.data.utils import get_tokenizer
import pickle

word_tokenizer = get_tokenizer('basic_english')
file = open("vocab", 'rb')
vocab = pickle.load(file)
file.close()

def pad_review(review, max_len):
    num_sents = len(review)
    for i in range(max_len - num_sents):
        review.append('<pad>')
    return review


def get_indices(sentence, max_sent_len):
    word_tokenizer = get_tokenizer('basic_english')
    tokens = word_tokenizer(sentence)
    indices = [vocab[token] for token in tokens]
    diff = max_sent_len - len(tokens)
    for i in range(diff):
        indices.append(1)  # padding idx=1
    return indices


def get_positions(text, max_review_len, max_sent_len):
    word_tokenizer = get_tokenizer('basic_english')
    num_sents = len(text)
    word_pos_indices = []
    review_pos_indices = []
    for i in range(max_review_len - num_sents):
        text.append('')
    for idx, sent in enumerate(text):
        tokens = word_tokenizer(sent)
        positional_indices = [i + 1 for i in range(len(tokens))]
        diff = max_sent_len - len(tokens)
        for i in range(diff):
            positional_indices.append(0)
        word_pos_indices.append(positional_indices)
        review_pos_indices.append(idx+1 if len(sent) > 1 else 0)
    return review_pos_indices, word_pos_indices


def yelp_collate(batch):
    max_num_sents = 0
    max_sent_len = 0
    review_len = []
    for sample in batch:
        num_sents = len(sample['text'])
        if num_sents > max_num_sents:
            max_num_sents = num_sents
        sent_len = []
        for sent in sample['text']:
            sent_len.append(len(word_tokenizer(sent)))
            if len(word_tokenizer(sent)) > max_sent_len:
                max_sent_len = len(word_tokenizer(sent))
        review_len.append(sent_len)

    for sample in batch:
        sample['review_pos_indices'], sample['word_pos_indices'] = get_positions(sample['text'], max_num_sents, max_sent_len)
        sample['text'] = pad_review(sample['text'], max_num_sents)
        sample['indices'] = []
        for sent in sample['text']:
            sample['indices'].append(get_indices(sent, max_sent_len))

    batch_dict = {'text': [], 'indices': [], 'category': [], 'review_pos_indices': [], 'word_pos_indices': []}
    for sample in batch:
        batch_dict['text'].append(sample['text'])
        batch_dict['indices'].append(sample['indices'])
        batch_dict['category'].append(sample['category'])
        batch_dict['review_pos_indices'].append(sample['review_pos_indices'])
        batch_dict['word_pos_indices'].append(sample['word_pos_indices'])

    batch_dict['indices'] = torch.tensor(batch_dict['indices'])
    batch_dict['review_pos_indices'] = torch.tensor(batch_dict['review_pos_indices'])
    batch_dict['word_pos_indices'] = torch.tensor(batch_dict['word_pos_indices'])
    batch_dict['category'] = torch.tensor(batch_dict['category'])
    batch_dict['lens'] = review_len

    return batch_dict
